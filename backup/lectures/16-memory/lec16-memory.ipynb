{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "external-thermal",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agile Hardware Design\n",
    "***\n",
    "# Intro to Design Optimization & Memory\n",
    "\n",
    "## Prof. Scott Beamer\n",
    "### sbeamer@ucsc.edu\n",
    "\n",
    "## [CSE 293](https://classes.soe.ucsc.edu/cse293/Winter22/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-consistency",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plan for Today\n",
    "\n",
    "* Intro to physical design (optimization)\n",
    "* Limitations of memories\n",
    "* Architectural interventions - banking, pipelining, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-registrar",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Optimize Physical Design?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-preservation",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Improve _Efficiency_!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-rochester",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The real question is when is the effort worth it?\n",
    "* Probably have _performance_ or _cost_ motivation, because otherwise writing software (to run on a processor) is probably much easier\n",
    "\n",
    "* Will optimize in various phases of the design and in various ways\n",
    "  * Keep an eye on cost/benefit ratio of this effort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-teaching",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Metrics to Optimize For?\n",
    "\n",
    "### Power\n",
    "* impacts battery life, thermals (heat), cost (energy bill and power supply)\n",
    "\n",
    "### Performance\n",
    "* how _fast_ it completes application goals \n",
    "\n",
    "### Area\n",
    "* chip (or FPGA) resources required, i.e. _cost_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-conference",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Need a Target/Goal for Optimization\n",
    "\n",
    "* Select an _implementation technology_ (e.g. specific ASIC process or FPGA)\n",
    "  * Unlike software, many optimizations will not be portable\n",
    "  * Tools also require some metrics as constraints (e.g. target clock rate or area)\n",
    "\n",
    "* **Measure first** before optimizing heavily\n",
    "  * Confirm optimization targets are actually problematic for PPA\n",
    "  * Also consider how much could be gained from optimization effort\n",
    "\n",
    "* A _hardware generator_ eases creation of many design alternatives\n",
    "  * Hard to know in advance which design configuration will be best\n",
    "  * A generator has a much better chance of being portable (i.e. useful) than a single design instance\n",
    "\n",
    "* Making _tradeoffs_ across all 3 (PPA) metric\n",
    "  * Need way to weigh tradeoffs between metrics (more later in week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-break",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some Differences Between Software Development & Chip Design\n",
    "\n",
    "### \"Easy\" World of Software Development\n",
    "* Much of effort goes into implementation (and verification)\n",
    "* Typically only one metric to optimize: _performance_\n",
    "  * Most performance optimizations are highly portable (e.g. most CPUs similar)\n",
    "* Tools (i.e. compilers) are highly automated and nearly never produce incorrect result\n",
    "\n",
    "### \"Hard\" World of Chip Design\n",
    "* After implementation, physical design optimization & verification are large hurdles\n",
    "* Multiple metrics to optimize for: _power_, _performance_, _area_ (PPA)\n",
    "  * Optimizations may be very technology dependent\n",
    "* Tools (i.e. tool flows) require _significant_ human intervention and oversight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-layout",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contrasting HW Design Philosophies\n",
    "* Actual design flows may vary (or have aspects of both), but present extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-dining",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Waterfall\n",
    "![tradtional loop](images/trad-hw.svg)\n",
    "\n",
    "* Complete stage before moving on\n",
    "* Late integration results in need to optimize & verify again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-tumor",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Agile\n",
    "![agile loop](images/agile-hw.svg)\n",
    "\n",
    "* Integrate & verify design early\n",
    "* Incrementally add features & optimize\n",
    "* Go around loop as many times as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-female",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Main Stages of Chip Design Tool Flow\n",
    "\n",
    "<img src=\"images/toolflow.svg\" alt=\"toolflow phases\" style=\"width:70%;margin-left:auto;margin-right:auto\"/>\n",
    "\n",
    "* Real tool flows much more complicated\n",
    "* Tools at different stages interact frequently & re-run\n",
    "  * Example: re-synthesize, place, and route a critical path\n",
    "* Many more steps at end for handling physical details and aiding manufacturing\n",
    "* Additionally, will want to verify design as it goes through these steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-domestic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Worry About Memory?\n",
    "\n",
    "### Memory can often contribute significantly to cost\n",
    "* Off-chip - price of memory components as well as pins to interface\n",
    "* On-chip - can consume significant area\n",
    "\n",
    "### Memory can also limit performance\n",
    "* Memory latency is well-known challenge for computer architecture\n",
    "* Limited memory bandwidth can cap overall throughput\n",
    "\n",
    "### What do we use memory for?\n",
    "* Hold application data and intermediate state\n",
    "* Think of memory as an all-purpose _\"connector\"_, i.e. a means to _communicate data in time_\n",
    "  * May not know producer/consumer relationship in advance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-directive",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory Terminology\n",
    "\n",
    "* _Capacity_ - size of storage (e.g. number of bits, bytes, words)\n",
    "* _Latency_ - time to retrieve data (or complete a write)\n",
    "* _Bandwidth_ - overall throughput (data/time e.g. bytes/second)\n",
    "* _Request_ - command sent to memory (i.e. read or write)\n",
    "* _Access width_ - amount of data transfered per request\n",
    "* _Port_ - means of accessing memory with a request\n",
    "  * Common types: read-only, write-only, or read/write\n",
    "* _Requests in flight_ - in progress requests that have been sent to memory\n",
    "\n",
    "<img src=\"images/terms.svg\" alt=\"memory terminology\" style=\"width:70%;margin-left:auto;margin-right:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-brook",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Little's Law\n",
    "\n",
    "### Parallelism = Throughput x Latency\n",
    "* Helpful tool for architects to reason about tradeoffs\n",
    "* Above terms are all for _average_ (e.g. average latency)\n",
    "* Often, one metric is fixed & you try to optimize another metric by improving third\n",
    "  * Example: latency is fixed but want to improve throughput => must increase parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-visit",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Practical Considerations & Constraints for Memory\n",
    "\n",
    "_**Goal**_ - reduce cost and performance deteriment of memory accesses\n",
    "\n",
    "_**Common pain points**_\n",
    "* Memory latency is too high\n",
    "* Too many ports requested\n",
    "* Can't provide desired bandwidth\n",
    "\n",
    "_**Typical approaches**_ and often architect's role\n",
    "* Reduce memory capacity demand and select densest (cheapest) technology to suffice\n",
    "* Increase latency tolerance (when possible) in design\n",
    "* Reduce bandwidth demands\n",
    "\n",
    "_**Memory technologies**_ typically trade off cost/density for performance & energy efficiency\n",
    "* Most expensive/fastest to cheapest/slowest: registers, SRAM, DRAM, PCM, flash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-damage",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Architectural Intervention: Banking Introduction\n",
    "\n",
    "* _Problem_ - application desires greater request bandwidth than feasible to implement\n",
    "  * Internally, the memory technology can only provide so many ports\n",
    "  * The memory latency has already been reduced as far as is reasonable for that technology\n",
    "\n",
    "* _Solution_ - _**banking**_\n",
    "  * Break up memory into multiple _banks_\n",
    "  * Each bank can service requests independently (increases request parallelism)\n",
    "  * If implemented, can often be _parameterized_ nicely\n",
    "\n",
    "<img src=\"images/banks-high.svg\" alt=\"banking high-level\" style=\"width:60%;margin-left:auto;margin-right:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-louisville",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Architectural Intervention: Banking Considerations\n",
    "\n",
    "* How to divide requests across banks?\n",
    "  * _Partition_ memory space across banks (e.g. N banks, each has 1/N of data)\n",
    "    * Send requests to proper bank by hashing address\n",
    "  * _Replicate_ data across banks (all banks hold same data)\n",
    "    * Most effective for increasing number of _read_ ports\n",
    "\n",
    "* Will banks have independent ports or share same port?\n",
    "  * _Independent_ ports - still need to know how to select correct port\n",
    "  * _Shared_ port - can time multiplex multiple requests on same port\n",
    "    * Most effective when access latency >> request latency\n",
    "    * Will need way to _tag_ requests to make responses clear\n",
    "\n",
    "* What about very large memories?\n",
    "  * A single memory has size limits, so banking is often inevitable\n",
    "  * Some applications add memory for capacity and end up with surplus bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-conversion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Smoothing Out Memory Bandwidth Demand\n",
    "\n",
    "* _Problem_ - cost (beyond capacity) is often proportional to _peak_ bandwidth demand\n",
    "  * Many applications are bursty in their use of memory bandwidth\n",
    "  * Ideally, would pay for _average_ bandwidth rather than peak\n",
    "\n",
    "* _Solution_ - _**smooth out**_ bandwidth demand over time\n",
    "  * Reduce burstiness so application is continously communicating\n",
    "  * Common approaches: _pipelining_ & _double buffering_\n",
    "\n",
    "<img src=\"images/traffic.svg\" alt=\"traffic burstiness\" style=\"width:70%;margin-left:auto;margin-right:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-position",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arch. Intervention - Overlap Communication & Computation\n",
    "\n",
    "* _Problem_ - compute is idle while memory is reading / writing\n",
    "\n",
    "* _Solution_ - overlap memory accesses (communication) with their use (computation)\n",
    "  * Definitely an example of _pipelining_\n",
    "  * Often requires more _parallelism,_ as need additional requests to send to memory while computing on current data\n",
    "\n",
    "<img src=\"images/overlap.svg\" alt=\"overlapping communication and computation\" style=\"width:80%;margin-left:auto;margin-right:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-revolution",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arch. Intervention - Double Buffering\n",
    "\n",
    "* _Problem_ - want to overlap communication & computation, but insuffient memory ports/bandwidth\n",
    "\n",
    "* _Solution_ - use two memories (_buffers_)\n",
    "  * Let compute work out of one memory\n",
    "  * Perform needed communication out of other memory\n",
    "  * Swap roles of memory when tasks complete\n",
    "\n",
    "<img src=\"images/double.svg\" alt=\"double buffering\" style=\"width:90%;margin-left:auto;margin-right:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-cycle",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instantiating Memory in Practice\n",
    "\n",
    "* _Off-chip memories_ (& interface) are carefully selected & planned\n",
    "\n",
    "* On-chip memory for ASIC - typically registers or SRAM\n",
    "  * SRAM arrays provided by foundry in preset sizes or from _memory compiler_\n",
    "  * Deliberately instantiate needed memory cells\n",
    "  * Will frequently want to codesign/tweak array sizes and architecture to match\n",
    "\n",
    "* On-chip memory on FPGA - typically registers, LUT RAM, BRAM, URAM\n",
    "  * Ideal: tools look at Verilog and _infer_ need for memory (more portable)\n",
    "  * Sometimes need to use intrinsics or give tools a \"nudge\"\n",
    "\n",
    "* Chisel describes behavior but not technology\n",
    "  * Typically sufficient for registers, and on FPGAs for BRAM/URAM\n",
    "  * For SRAM, typically instantiate _blackbox_ to wrap interface of provided array\n",
    "  * Chisel can specify a read/write port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-divide",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary - Physical Design Intro + Memory Optimization\n",
    "\n",
    "* Before designing hardware or optimizing it...\n",
    "  * know why need to build hardware rather than programming a CPU\n",
    "  * measure PPA and compare to goal\n",
    "* Close the loop early - find issues with design + backend tools early\n",
    "  * More iterations through tools gives more opportunities to optimize\n",
    "* Little's Law is a handy way to reason about latency, throughput, and parallelism\n",
    "* Optimizing memory (off-chip or on-chip) should be done first\n",
    "  * Can have a big impact on cost\n",
    "  * Changing memory type (or organization) can require big changes, so don't want to do late in process\n",
    "  * _Optimizations:_ banking, traffic shaping, comm. + comp. overlap, double buffering"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
